\section{Related Work}
In this section we discuss related work with respect to the efficiency of technical review meetings and the relevance of the meeting sessions. Prior work has qualitatively analyzed the technical review process used by large software systems.

\subsection{Review without meeting session}
Without a review meeting the reviewers would just send their list of findings via tools developed for supporting code review to the author of the artifact or choose one reviewer to take care of all the review work. The following papers show the influence on the quality of the artifact when using this method. \\* 
Baker discussed a procedure for reviewing code changes that are made to a software product as it moves through its life cycle. Facing a decline of customer confidence in his product his team came up with the idea of using a revision control system to identify all changes made to the product and a line by line review of the changes by the project manager. He noted that this methodology came with several advantages one of them being the efficiency with which the quality improvement was made. A single reviewer becomes very efficient in his reviews due to practice at reviewing code and to a thorough understanding of the product. The fact they used the product manager as the single reviewer facilitated him getting an insight into the whole project encompassing each engineer's performance, the complexity of the tasks, progress of the project and also bettering his scheduling skills. The employees liked this methodology because of the manager getting an understanding of the effort in their work, capabilities and identifying areas that needed improvement. \\*
By using this methodology a 40\% reduction in the number of bugs at a cost of 1-2\% of the project was achieved \cite{Baker:1997:CRE:253228.253461}. \\*
Mcintosh et al. studied the relationship between software quality and:
\begin{itemize}
	\item the proportion of changes that have been code reviewed (code review coverage), and
	\item the degree of reviewer involvement in the code review process (code review participation)
\end{itemize}
through a case study of the large Qt, VTK, and ITK open source systems. The Gerrit-driven code review process for git-based software projects has been used which is tightly integrated with test automation and code integration tools. They extracted code review data from the Gerrit review databases of the studied systems and linked the review data to the integrated patches recorded in the corresponding version control systems. They built Multiple Linear Regression (MLR) models to explain the incidence of post-release defects detected in the components of the studied systems having the goal to understand the relationship between the explanatory variables (code review coverage and participation) and the dependent variable (post-release defect counts). \\*
They found out that low code review coverage and participation are estimated to produce components with up to two and five additional post-release defects respectively \cite{McIntosh:2014:ICR:2597073.2597076}. \\*
Bacchelli et al. empirically explored the motivations, challenges, and outcomes of tool-based code reviews. They observed, interviewed, and surveyed developers and managers and manually classified hundreds of review comments across diverse teams at Microsoft using discussions within the review tool CodeFlow. They found out that the main motivation for reviews despite finding defects are knowledge transfer, increasing team awareness, and creation of alternative solutions to problems \cite{Bacchelli:2013:EOC:2486788.2486882}. \\*
Meyer discussed the importance of code review meetings in the age of the internet saying that new collaboration tools allow geographically distributed software-development teams to boost the venerable concept of code review. Seeing it almost as an impossibility to have all the people involved at a same time in the same room they used several communication tools to allow several threads of discussion to cover code, design and specification as well. Criticizing the traditional code review meeting process by saying that in an extreme programming point reviews may be superfluous in projects practicing pair programming, also when it comes to finding code flaws static analysis tools being more effective than human inspection and that the meeting process is time consuming, he still acknowledges that code reviews remain an important tool when adapted to the modern world of software development by including abstract program interface (API) design, architecture choices, and other specification and design issues to the review meetings. Another point they make is that a physical meeting among people in the same room is becoming hardly applicable since distributed teams spread over many locations and time zones and that distributed reviews are possible with the right tools. They used a combination of tools including X-Lite, a voice communication similar to a conference call, Skype for written communication, Google Docs for shared documents and WebEx, a sharing tool for sharing screens. This brought many advantages one of them being saving time by updating the document in Google Docs in real time during the meeting, preparing the shared document with links to the actual code a week ahead of the review and providing their comments on the review page (the shared document) prior to the meeting with the code author then responding just below the comments on the same page \cite{Meyer_2008}. \\*
McCarthy et al. designed and conducted a controlled experiment in the spring of 1995 with 21 subjects acting as reviewers with the goals being to characterize the behaviour of existing approaches, and to assess the potential benefits of meetingless inspections. The three inspection methods were:
\begin{itemize}
	\item every reviewer individually analyzes the artifact with no detecting defects but preparing it for the review meeting (PI)
	\item each reviewer analyzes the artifact with detecting as many defects as possible, inspecting the document in a review meeting (DC)
	\item each reviewer analyzes the artifact with the goal of detecting as many defects as possible, then again repeat this procedure a second time with not review meeting (DD)
\end{itemize}
The experiment manipulated four independent variables:
\begin{itemize}
	\item The inspection method (PI, DC or DD)
	\item The inspection round (each reviewer participated in two inspections during the experiment)
	\item The specification to be inspected (two were used during the experiment)
	\item The order in which the specifications were inspected (Either specification could be inspected first)
\end{itemize}
For each inspection they measured three dependent variables:
\begin{itemize}
	\item The individual defect detection rate
	\item The team defect detection rate
	\item The gain rate, that is, the percentage of defects initially identified during the second phase of the inspection
\end{itemize}
They found out that the inspection method used cannot be ignored as a significant source of variation in the meeting gain rates and that the meetingless inspections detected more new defects in the second phase of the inspection than did inspections using the other methods and that overall more defects were found than in inspections with meetings \cite{mccarthy1996experiment}. \\*
Votta determined the proportion of defects found during the inspection that were originally discovered at the meeting (meeting gain rate) to quantify the usefulness of inspection meetings in a case study of 13 design inspections at the American Telephone and Telegraph Company (AT\&T). The result was that the meeting gain rate for these inspections was ~5\%, meaning that review meetings are not effective at all \cite{votta1993does}. \\*
Porter et al. did another study collecting data on meeting gains, also at AT\&T involving \textgreater 100 code inspections observing many meetings producing no gains at all, while some having rates of 80\% with an average meeting gain rate of 33\% \cite{porter1995experiment}. \\*
Porter et al. reported that although the effectiveness of software inspection is valid their economics remain uncertain figuring out that the benefits of inspections are often overstated and the costs, especially large software development projects, are understated pointing to the fact that some of the most influential studies establishing these costs and benefits are 20 years old now \cite{porter1996review}.
